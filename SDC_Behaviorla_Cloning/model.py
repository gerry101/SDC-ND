# -*- coding: utf-8 -*-
"""SDC_Behavioral_Cloning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tCPcJDrWuJSmg8xLHWEpnZeQLPla6W0i
"""

# Commented out IPython magic to ensure Python compatibility.
# Import libraries

# %tensorflow_version 2.x

import csv
import numpy as np
import numpy as np
import tensorflow as tf
from tensorflow import keras
from PIL import Image
import matplotlib.pyplot as plt

# Extract image data

!unzip -q "/content/IMG.zip"

# Read sample data from images csv file

with open("/content/driving_log.csv") as csv_file:
    csv_reader = csv.reader(csv_file, delimiter=',')
    line_count = 0

    print("\nColumns are: Center Image, Left Image, Right Image, Steering Angle, Throttle, Brake, Speed\n")

    for row in csv_reader:
        if line_count < 10:
            print(f'{", ".join(row)}')
            line_count += 1

    print(f'\nProcessed {line_count} lines.')

# Define final training data
X = []
y = []

# Initialize image data and labels - center

with open("/content/driving_log.csv") as csv_file:
    csv_reader = csv.reader(csv_file, delimiter=',')
    line_count = 0

    print("\nColumns are: Center Image, Left Image, Right Image, Steering Angle, Throttle, Brake, Speed\n")

    for row in csv_reader:
        # Center
        center_img_path = row[0].split("/")[-1]
        center_img = Image.open("/content/IMG/" + center_img_path)
        X.append(np.array(center_img))
        y.append(float(row[3]))
        center_flip = np.fliplr(np.array(center_img))
        X.append(center_flip)
        y.append(float(row[3]) * -1)

        line_count += 1

    print(f'\nProcessed {line_count} center images.')

# Initialize image data and labels - left

with open("/content/driving_log.csv") as csv_file:
    csv_reader = csv.reader(csv_file, delimiter=',')
    line_count = 0

    for row in csv_reader:
        # Left
        left_img_path = row[1].split("/")[-1]
        left_img = Image.open("/content/IMG/" + left_img_path)
        X.append(np.array(left_img))
        y.append(float(row[3]) + 0.3)
        left_flip = np.fliplr(np.array(left_img))
        X.append(left_flip)
        y.append((float(row[3]) * -1) - 0.2)

        line_count += 1

    print(f'\nProcessed {line_count} left images.')

# Initialize image data and labels - right

with open("/content/driving_log.csv") as csv_file:
    csv_reader = csv.reader(csv_file, delimiter=',')
    line_count = 0

    for row in csv_reader:
        # Right
        right_img_path = row[2].split("/")[-1]
        right_img = Image.open("/content/IMG/" + right_img_path)
        X.append(np.array(right_img))
        y.append(float(row[3]) - 0.2)
        right_flip = np.fliplr(np.array(right_img))
        X.append(right_flip)
        y.append((float(row[3]) * -1) + 0.2)

        line_count += 1

    print(f'\nProcessed {line_count} right images.')

# Shape and inspect data

X = np.asarray(X)
y = np.asarray(y)

print("Total images shape:", X.shape)
print("Total labels shape:", y.shape)

# Visualize random samples of road images

print("\tSample Road Images\n")
fig, ax = plt.subplots(1, 6, figsize=(20, 20))
for row in ax:
    rand_img = np.random.randint(0, len(X))
    row.imshow(np.squeeze(X[rand_img]))
plt.show()

# Visualize image label distribution

plt.title("Road Images Label Distribution")
plt.plot(list(range(len(X))), y)
plt.show()

# Create the model

model = tf.keras.Sequential([
          tf.keras.layers.Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160, 320, 3)),
          tf.keras.layers.Cropping2D(cropping=((50, 20), (0, 0))),
          tf.keras.layers.Conv2D(128, (5, 5), activation="relu"),
          tf.keras.layers.MaxPooling2D(3, 3),
          tf.keras.layers.Conv2D(64, (5, 5), activation="relu"),
          tf.keras.layers.MaxPooling2D(3, 3),
          tf.keras.layers.Conv2D(64, (5, 5), activation="relu"),
          tf.keras.layers.MaxPooling2D(3, 3),
          tf.keras.layers.Flatten(),
          tf.keras.layers.Dense(1),  
        ])

# Model summary

model.summary()

# Epoch callback class

class epochCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs = {}):
        if(logs.get('val_loss') < 0.024):
            epoch_val_loss = logs.get('val_loss')
            print(f'\n\nModel validation loss currently at {epoch_val_loss}. Stopping training...\n\n')
            self.model.stop_training = True

# Compile the model

model.compile(loss="mean_squared_error", optimizer="adam")

# Fit the model

history = model.fit(X, y, epochs=1, validation_split=0.2, shuffle=True, callbacks = [epochCallback()])

# Save the model

model.save("driver.h5")